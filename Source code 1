# -*- coding: utf-8 -*-
"""Demand_Forecasting

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cZHMeaqKscSpE145-ilcmt1o27E7ooDn
"""

# üìå Import Required Libraries
import pandas as pd
import numpy as np
import joblib
import xgboost as xgb
import matplotlib.pyplot as plt
from google.colab import files
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error

# üìå Step 1: Upload and Load CSV Files
uploaded_files = files.upload()

# Merge all uploaded files into a single dataset
df_list = [pd.read_csv(filename) for filename in uploaded_files.keys()]
df_combined = pd.concat(df_list, ignore_index=True)

# Convert 'Date' column to datetime
df_combined['Date'] = pd.to_datetime(df_combined['Date'], format='%b-%y', errors='coerce')

# Fill missing values in SellingPrice with SKU-wise median
df_combined['SellingPrice'] = df_combined.groupby('SKU')['SellingPrice'].transform(lambda x: x.fillna(x.median()))

# üìå Step 2: Inspect Available Columns
print("\nüìù Columns Available in the Dataset:")
print(df_combined.columns)

# üìç Check if 'Location' exists in columns or if we need to select another column
location_column = None
for column in df_combined.columns:
    if "location" in column.lower():  # Handle case-insensitive search for location
        location_column = column
        break

if location_column:
    print(f"\n‚úÖ Found location column: {location_column}")
else:
    print("\n‚ùå No 'Location' column found automatically. Please select the column manually.")
    location_column = input("Enter the name of the location column: ").strip()

# üìå Step 3: Check Available Locations
print("\nüìç Available Locations or 'Overall':")
if location_column and location_column in df_combined.columns:
    # Extract unique location names and sort them
    locations = df_combined[location_column].dropna().unique()
    locations = sorted(set(locations))  # Remove duplicates and sort

    # Display the locations
    print(f"0. Overall (all locations combined)")
    for idx, location in enumerate(locations, 1):
        print(f"{idx}. {location}")

    # Allow user to select a location or 'Overall'
    location_option = int(input(f"Select a location or 'Overall' by entering a number (0-{len(locations)}): "))

    if location_option == 0:
        print(f"‚úÖ Using data for all locations combined.")
    elif 1 <= location_option <= len(locations):
        selected_location = locations[location_option - 1]
        print(f"‚úÖ Filtering data for location: {selected_location}")
        df_combined = df_combined[df_combined[location_column] == selected_location]
    else:
        print("‚ùå Invalid location option.")
else:
    print("‚ùå No valid 'Location' column found in the dataset.")

# üìå Step 4: Ask User for Historical Data Window
print("\nüìä Choose Historical Data Duration:")
print("1Ô∏è‚É£ Last 3 Months\n2Ô∏è‚É£ Last 6 Months\n3Ô∏è‚É£ Last 12 Months")
option = input("Enter 1, 2, or 3: ")

history_months = {"1": 3, "2": 6, "3": 12}
selected_months = history_months.get(option, 3)  # Default to 3 months

# Filter dataset to include only the selected historical period
latest_date = df_combined['Date'].max()
start_date = latest_date - pd.DateOffset(months=selected_months)
df_filtered = df_combined[df_combined['Date'] >= start_date]

print(f"‚úÖ Using last {selected_months} months of data for training.")

# üìå Step 5: Feature Engineering
df_filtered['Year'] = df_filtered['Date'].dt.year
df_filtered['Month'] = df_filtered['Date'].dt.month
df_filtered['Quarter'] = df_filtered['Date'].dt.quarter

# Define Season
def get_season(month):
    if month in [12, 1, 2]: return "Winter"
    elif month in [3, 4, 5]: return "Summer"
    elif month in [6, 7, 8]: return "Monsoon"
    else: return "Festival"

df_filtered['Season'] = df_filtered['Month'].apply(get_season)

# One-Hot Encoding for Season
df_filtered = pd.get_dummies(df_filtered, columns=['Season'])

# Ensure all seasons exist in DataFrame (to avoid missing column errors)
for season in ["Winter", "Summer", "Monsoon", "Festival"]:
    col = f"Season_{season}"
    if col not in df_filtered.columns:
        df_filtered[col] = 0

# Create Lag Features
df_filtered['Sales_Lag1'] = df_filtered.groupby('SKU')['Sales'].shift(1)

# Create Moving Averages
df_filtered['Sales_MA3'] = df_filtered.groupby('SKU')['Sales'].rolling(3).mean().reset_index(0, drop=True)
df_filtered['Sales_MA6'] = df_filtered.groupby('SKU')['Sales'].rolling(6).mean().reset_index(0, drop=True)

# Fill missing values
df_filtered.fillna(0, inplace=True)

print("‚úÖ Feature Engineering Completed!")

# üìå Step 6: Define Features & Target
features = ['Sales_Lag1', 'Sales_MA3', 'Sales_MA6', 'OpeningStock', 'SellingPrice', 'Year', 'Month', 'Quarter',
            'Season_Monsoon', 'Season_Summer', 'Season_Winter']

X = df_filtered[features]
y = df_filtered['Sales']

# Ensure all data is numeric
X = X.apply(pd.to_numeric, errors='coerce')
y = pd.to_numeric(y, errors='coerce')

# Fill missing values
X.fillna(0, inplace=True)
y.fillna(0, inplace=True)

# üìå Step 7: Split into Train & Test Set
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False, random_state=42)

# Convert to NumPy arrays
X_train, X_val = X_train.to_numpy(), X_val.to_numpy()
y_train, y_val = y_train.to_numpy(), y_val.to_numpy()

print("‚úÖ Training Data Prepared!")

# üìå Step 8: Train XGBoost Model
model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=5)
model.fit(X_train, y_train)

# Save Model
joblib.dump(model, "/content/sales_forecasting_xgboost.pkl")
print("‚úÖ Model Trained & Saved!")

# üìå Step 9: Model Evaluation
y_pred = model.predict(X_val)

mae = mean_absolute_error(y_val, y_pred)
rmse = np.sqrt(mean_squared_error(y_val, y_pred))

print(f"üìä Model Performance:\n MAE: {mae:.2f} | RMSE: {rmse:.2f}")

# üîπ Graph: Actual vs. Predicted Sales
plt.figure(figsize=(12,6))
plt.plot(y_val, label="Actual Sales", color='blue')
plt.plot(y_pred, label="Predicted Sales", color='red', linestyle='dashed')
plt.xlabel("Time")
plt.ylabel("Sales")
plt.title("Actual vs. Predicted Sales")
plt.legend()
plt.show()

# üìå Step 10: Recursive Future Sales Prediction
print("\nüîÆ Predicting Future Sales for Next 3 Months...\n")

# Load trained model
loaded_model = joblib.load("/content/sales_forecasting_xgboost.pkl")

# Start from last available data
latest_data = df_filtered.iloc[-1].copy()

future_sales = []
for i in range(1, 4):
    latest_data["Month"] += 1  # Move to next month
    if latest_data["Month"] > 12:  # Handle year change
        latest_data["Month"] = 1
        latest_data["Year"] += 1

    # Update quarter
    latest_data["Quarter"] = (latest_data["Month"] - 1) // 3 + 1

    # Update season
    season = get_season(latest_data["Month"])
    for s in ["Winter", "Summer", "Monsoon", "Festival"]:
        latest_data[f"Season_{s}"] = 1 if s == season else 0

    # Prepare input for prediction
    input_data = latest_data[features].to_numpy().reshape(1, -1)

    # Predict next month's sales
    prediction = loaded_model.predict(input_data)[0]
    future_sales.append(prediction)

    # Update lag & moving average features for the next iteration
    latest_data["Sales_Lag1"] = prediction
    latest_data["Sales_MA3"] = (latest_data["Sales_MA3"] * 2 + prediction) / 3
    latest_data["Sales_MA6"] = (latest_data["Sales_MA6"] * 5 + prediction) / 6

# Display Forecasted Sales
for i, sales in enumerate(future_sales, 1):
    print(f"üìà Forecasted Sales for Month {i}: {sales:.2f}")

# Identify Best Selling Product
top_product = df_filtered.groupby('SKU')['Sales'].sum().idxmax()
print(f"üî• Top-Selling Product in the Upcoming Months: {top_product}")
